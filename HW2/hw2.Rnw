\documentclass[12pt, oldfontcommands]{article}
\usepackage[english]{babel}
%\usepackage[brazilian, brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{graphicx}
\usepackage[top = 2cm, left = 2cm, right = 2cm, bottom = 2cm]{geometry}
\usepackage{indentfirst}
\usepackage{float}
\usepackage{multicol}
\usepackage[normalem]{ulem}
\usepackage{breqn}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{threeparttable}
\setlength\parindent{0pt}
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}

\title{  
 \normalfont \normalsize 
 \textsc{AMCS 210 - Applied Statistics and Data Analysis} \\
 Hernando Catequista Ombao \\
 Applied Mathematics and Computational Sciences Program \\
 Computer, Electrical and Mathematical Sciences \& Engineering (CEMSE) Division \\
 King Abdullah University of Science and Technology (KAUST) \\[25pt]
 \horrule{.5pt} \\ [.4cm]
 \LARGE HOMEWORK \\
  2
 \horrule{2pt} \\[ .5cm]}
 
\author{Henrique Aparecido Laureano}
\date{\normalsize Fall Semester 2017}

\begin{document}

\maketitle

\vspace{\fill}

\tableofcontents

\horrule{1pt} \\

\newpage

<<setup, include=FALSE>>=
# <code r> ===================================================================== #
library(knitr)

tema <- knit_theme$get("acid")

knit_theme$set(tema)

opts_chunk$set(size='small'
               , cache=TRUE
               , cache.path='cache/'
               , comment=NA
               , warning=FALSE
               , message=FALSE
               , fig.align='center'
               , dpi=100
               , fig.path='iBagens/'
               , fig.pos='H'
               , background='#ffffff'
               , results='hold'
               , fig.show='hold')
# </code r> ==================================================================== #
@

\section*{Exercise 1} \addcontentsline{toc}{section}{Exercise 1}

\horrule{1pt} \\

\textbf{A politician running for office is interested in estimating the
        proportion among legal residents of the state of California who support
        the DREAMER’s act (which we denote as \(\pi\)). An organization was
        instructed to conduct a poll with the constraint that the estimator should
        be within a tolerance limit of 0.05.} \\
        
\textbf{Suppose that the true population proportion of supporters is
        \(\pi\) = 0.65. The organization is now at a planning stage to determine
        the desired sample size so that there is only a slim chance of 10\% that
        an estimator (sample proportion) falls outside of the designated tolerance
        limit (i.e., it falls outside of 0.60 and 0.70).}

\subsection*{(a)} \addcontentsline{toc}{subsection}{(a)}

\textbf{Conduct a simulation study to determine if a sample size of n = 200
        respondents will be sufficient to meet the target? As a guide to
        approaching this problem: (i.) simulate at least B = 10.000 samples each
        of size n = 200 from a binomial distribution; (ii.) for each sample record
        the sample proportion; (iii.) determine the proportion (out B = 10.000
        samples) of sample proportion that fall within the designated tolerance
        limit.} \\

\underline{Solution:}

<<>>=
# <code r> ===================================================================== #
## defining some variables
n <- 200 # sample size
B = 1e4 # number of replications
p <- .65 # true proportion
tol <- .05 # tolerance level
in_inter <- numeric(B) # creating empth object of size B

## simulation study code
for (i in 1:B){
  samp <- rbinom(1, n = n, p = p) # simulating samples from a binomal dist.
  prop <- mean(samp) # sample proportion
  abs_samp <- abs(prop - p) # difference to the tolerance level
  in_inter[i] <- ifelse(abs_samp <= tol, "in", "out") # if is in or out
}
# proportion of sample proportion that fall within (or out) the tol. level
prop.table(table(in_inter))
# </code r> ==================================================================== #
@

The proportion is of 14\%, bigger than the desired proportion of 10\%.

\subsection*{(b)} \addcontentsline{toc}{subsection}{(b)}

\textbf{If the sample size of n = 200 does not satisfy the requirement above
        continue with procedure of finding the smallest sample size that would
        satisfy the tolerance limit.} \\

\underline{Solution:}

<<fig.width=10, fig.height=5.25, fig.cap="Sample sizes vs. tolerance limits.">>=
# <code r> ===================================================================== #
final_prop <- prop.table(table(in_inter)) ; prop_out <- final_prop[[2]]
while (final_prop[[2]] > .1){
  for (i in 1:B){
    samp <- rbinom(1, n = n + 1, p = p)
    prop <- mean(samp) ; abs_samp <- abs(prop - p)
    in_inter[i] <- ifelse(abs_samp <= tol, "in", "out")}
  final_prop <- prop.table(table(in_inter))
  prop_out[length(prop_out)+1] <- final_prop[[2]] ; n <- n + 1}
library(latticeExtra)
xyplot(prop_out ~ 200:n, type = c("h", "p"), pch = 16
       , xlab = "Sample size", ylab = "Tolerance limit"
       , main = paste0(
         "Smallest sample size: ", n, " (tolerance limit: ", min(prop_out), ")")
       , scales = list(x = list(at = c(200, n)))
       , panel = function(...){
         panel.abline(h = .1, col = 2, lty = 2)
         panel.xyplot(...)
         panel.segments(n, 0, n, min(prop_out), col = 2, lwd = 2)
         panel.points(n, min(prop_out), col = 2, pch = 16)})
# </code r> ==================================================================== #
@

\section*{Exercise 2} \addcontentsline{toc}{section}{Exercise 2}

\horrule{1pt} \\

\textbf{Exercises on calculating binomial probabilities. Let \(X\) be a binomial
        random variable with n = 5 and probability parameter \(\pi\) = 0.3. Think
        of this as counting the number of heads obtained by tossing n = 5
        identical coins each of which has the probability of \(\pi\) = 0.3 that it
        lands in heads.}

\begin{itemize}
 \item Enumerate the elements of the sample space of \(X\).
\end{itemize}

\underline{Solution:}

\begin{itemize}
 \item Obtain the table of probability mass function, i.e., compute the
       probabilities \(\mathbb{P}(X = x)\) for each \(x\) in the sample space.
\end{itemize}

\underline{Solution:}

\begin{itemize}
 \item Compute \(\mathbb{P}(X \geq 4)\).
\end{itemize}

\underline{Solution:}

\begin{itemize}
 \item Compute \(\mathbb{P}(X < 3)\).
\end{itemize}

\underline{Solution:}

<<warning=FALSE>>=
# <code r> ===================================================================== #
(snore <- read.table("~/Dropbox/CLASS-DROPBOX/BOOK-DATA/snoreData.txt", skip = 1
                     , header = TRUE))
# </code r> ==================================================================== #
@

<<fig.height=5.75, fig.width=10, fig.cap="(a) Total number of people and number of people with heart disease by level of severity; (b) Proportion (people with heart disease/total) of people with heart disease by level of severity.">>=
# <code r> ===================================================================== #
library(latticeExtra)
print(
  barchart(total + heart_disease ~ factor(snoring_severity), snore
           , col = c("#0080ff", "gray60"), border = "transparent"
           , xlab = "Snoring severity", ylab = "Number of people"
           , scales = list(y = list(at = c(30, sort(snore$total))))
           , main = "Total numbers by level of severity", sub = "(a)"
           , key = list(corner = c(.9, .9)
                        , text = list(c("Total number", "Heart disease"))
                        , rectangle = list(border = "transparent")
                        , col = c("#0080ff", "gray60"))
           , panel = function(...){
             panel.abline(h = c(30, sort(snore$total)), col = "gray50", lty = 2)
             panel.barchart(...)
           }), position = c(0, 0, .5, 1), more = TRUE)
print(
  barchart(heart_disease/total ~ factor(snoring_severity), snore
           , col = "#0080ff", border = "transparent"
           , xlab = "Snoring severity", ylab = "Rate"
           , main = "Prop. of people with heart disease by level of severity"
           , sub = "(b)", scales = list(y = list(draw = FALSE))
           , panel = function(...){
             args <- list(...)
             panel.text(args$x, args$y, paste0(round(args$y*100, 2),"%"), pos = 3)
             panel.barchart(...)
           }), position = c(.5, 0, 1, 1))
# </code r> ==================================================================== #
@

A big part, more than half, was classified by the spouses as a low degree of
snoring severity. In this low levels the percentage of heart disease is very low
(2, 5\%). In the biggest degree, 5, the rate of heart disease is bigger, almost
12\%, the double of the observed in the degree 2.

\section*{Exercise 3} \addcontentsline{toc}{section}{Exercise 3}

\horrule{1pt} \\

\textbf{Download the “calcium” data set from the course website. Provide the
        summary statistics (mean, standard deviation, and 5-number data summaries)
        and the histograms of variables “Begin” and “End”. Which variable is
        higher on average, and which one is more dispersed? Calculate the variance
        of “End” for the placebo group manually; i.e., by first calculating the
        deviations from the mean. Provide the boxplots of variables “Begin” and
        “End” for different “Treatment” groups (i.e., calcium and placebo). In one
        paragraph, discuss your findings based on these graphs.} \\

\underline{Solution:}

<<warning=FALSE>>=
# <code r> ===================================================================== #
(calcium <- read.table("~/Dropbox/CLASS-DROPBOX/BOOK-DATA/calcium.txt"
                       , header = TRUE, sep = ","))
# </code r> ==================================================================== #
@

Minimum, 1st quartile, median, mean, 3rd quartile and maximum:

<<>>=
# <code r> ===================================================================== #
summary(calcium[ , -1])
# </code r> ==================================================================== #
@

Standard deviation:

<<>>=
# <code r> ===================================================================== #
sd(calcium$Begin) ; sd(calcium$End)
# </code r> ==================================================================== #
@

Histograms:

<<fig.width=10, fig.height=5.75, fig.cap='(a) Histogram of the "Begin" variable; (b) Histogram of the "End" variable.'>>=
# <code r> ===================================================================== #
par(mfrow = c(1, 2), mar = c(3, 4, 4, 2))
hist(calcium$Begin, col = "#0080ff", border = "orange", las = 1, xlab = ""
     , main = "Begin\n(a)", xlim = c(90, 140))
hist(calcium$End, col = "#0080ff", border = "orange", las = 1, xlab = ""
     , main = "End\n(b)", xlim = c(90, 140))
# </code r> ==================================================================== #
@

In average, the variable "Begin" is higher, but both are very similar. The
variable "End" is more dispersed, but with the same commentary, both the variables
are very similar (standard deviations very closer to each other). \\

Variance of "End" for the placebo group:

<<>>=
# <code r> ===================================================================== #
(x <- calcium[calcium$Treatment == "Placebo", ]$End)

(x_bar <- mean(x))
# </code r> ==================================================================== #
@
<<>>=
# <code r> ===================================================================== #
(deviations <- x - x_bar)
# </code r> ==================================================================== #
@
<<>>=
# <code r> ===================================================================== #
(variance <- sum(deviations**2)/(length(x)-1)) ; variance == var(x)
# </code r> ==================================================================== #
@

<<fig.width=10, fig.height=4.5, fig.cap='(a) Boxplot for the variable "Begin" in the group Calcium; (b) Boxplot for the variable "End" in the group Calcium; (c) Boxplot for the variable "Begin" in the group Placebo; (d) Boxplot for the variable "End" in the group Placebo.'>>=
# <code r> ===================================================================== #
par(mfrow = c(1, 4), mar = c(1, 4, 4, 2))
boxplot(calcium[calcium$Treatment == "Calcium", ]$Begin, las = 1
        , main = "Calcium (a)\n(Begin)", ylim = c(90, 140))
boxplot(calcium[calcium$Treatment == "Calcium", ]$End, las = 1
        , main = "Calcium (b)\n(End)", ylim = c(90, 140))
boxplot(calcium[calcium$Treatment == "Placebo", ]$Begin, las = 1
        , main = "Placebo (c)\n(Begin)", ylim = c(90, 140))
boxplot(calcium[calcium$Treatment == "Placebo", ]$End, las = 1
        , main = "Placebo (d)\n(End)", ylim = c(90, 140))
# </code r> ==================================================================== #
@

We don't see much difference between "Begin" and "End" or between Calcium and 
Placebo. The biggest values are observed in the treatment Calcium in the "Begin",
and the smallest values in the treatment Placebo in the "End". We see the smallest
variance in the treatment Calcium in the "End", and the biggest variance in the
treatment Placebo in the "End". Even with this findings, we reiterate that the
differences are very small between the treatments and variables.

\section*{Exercise 4} \addcontentsline{toc}{section}{Exercise 4}

\horrule{1pt} \\

\textbf{Download the “wdbc” data set. Provide a bar graph for the discrete
        variable, and scatter plots for each pair of continuous variables. Provide
        the box plots of continuous variables for each level of “Diagnosis”. In
        one paragraph, discuss your findings based on these graphs.} \\

\underline{Solution:}

<<fig.width=10, fig.height=4.25, fig.cap='Frequency and percentage for each level of "Diagnosis".'>>=
# <code r> ===================================================================== #
library("kdevine") ; data(wdbc)

barchart(wdbc$diagnosis, col = "#0080ff", xlab = "Frequency", xlim = c(0, 410)
         , scales = list(x = list(draw = FALSE)
                         , y = list(labels = c("Benign", "Malignant")))
         , border = "transparent", main = "Diagnosis"
         , panel = function(...){
           args <- list(...)
           panel.text(args$x, args$y, pos = 4
                      , paste0(args$x," (", round(prop.table(args$x),3)*100,"%)"))
           panel.barchart(...)})
# </code r> ==================================================================== #
@

This dataset contain measurements on cells in suspicious lumps in a women's
breast. Variables are computed from a digitized image of a fine needle aspirate
(FNA) of a breast mass. They describe characteristics of the cell nuclei present
in the image. All samples are classsified as either \textit{benign} or
\textit{malignant}. \\

Ten real-valued variables are computed for each cell nucleus. \\

The mean, standard error, and "worst" or largest (mean of the three largest
values) of these variables were computed for each image, resulting in 30
variables. \\

This breast cancer database was obtained from the University of Wisconsin
Hospitals, Madison from Dr. William H. Wolberg. \\

Thus, we provide the scatter plots for each pair of variables divided by the
mean, standard error and "worst" values, resulting in this way in three scatter
plot matrices.

\vspace{1.75cm}

<<fig.width=10, fig.height=10, fig.cap="Scatter plots for each pair of mean variables in the lower triangular part of the matrix, in the upper triangular part we have the respectives correlations between the variables. In blue we have the corresponding observations to the benign diagnosis and in gray the corresponding observations to the malignant diagnosis.">>=
# <code r> ===================================================================== #
panel.cor <- function(x, y, ...){
  usr <- par("usr")
  on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y))
  txt <- format(c(r, 0.123456789), digits = 2)[1]
  text(0.5, 0.5, txt, cex = .8/strwidth(txt))
}
rotulos <- tm::removeWords(names(wdbc[2:11]), "mean ")
rotulos[c(5:6, 8, 10)] <- c("smooth", "compact", "concave", "fractal d.")

pairs(wdbc[2:11]
      , pch = 16
      , gap = .25
      , las = 1
      , upper.panel = panel.cor
      , col = c("#0080ff", "gray30")[unclass(wdbc$diagnosis)]
      , labels = rotulos
      , font.labels = 2
      , main = "Mean")
# </code r> ==================================================================== #
@

\vspace{-.5cm}
<<fig.width=10, fig.height=10, fig.cap='Scatter plots for each pair of "worst" variables in the lower triangular part of the matrix, in the upper triangular part we have the respectives correlations between the variables. In blue we have the corresponding observations of the benign diagnosis and in gray the corresponding observations of the malignant diagnosis.'>>=
# <code r> ===================================================================== #
rotulos <- tm::removeWords(names(wdbc[12:21]), "worst ")
rotulos[c(5:6, 8, 10)] <- c("smooth", "compact", "concave", "fractal d.")

pairs(wdbc[12:21], pch = 16, gap = .25, las = 1, upper.panel = panel.cor
      , col = c("#0080ff", "gray30")[unclass(wdbc$diagnosis)]
      , labels = rotulos, font.labels = 2, main = '"Worst"')
# </code r> ==================================================================== #
@

<<fig.width=10, fig.height=10, fig.cap="Scatter plots for each pair of standard error variables in the lower triangular part of the matrix, in the upper triangular part we have the respectives correlations between the variables. In blue we have the corresponding observations to the benign diagnosis and in gray the corresponding observations to the malignant diagnosis.">>=
# <code r> ===================================================================== #
rotulos <- tm::removeWords(names(wdbc[22:31]), "sd ")
rotulos[c(5:6, 8, 10)] <- c("smooth", "compact", "concave", "fractal d.")
pairs(wdbc[22:31], pch = 16, gap = .25, las = 1, upper.panel = panel.cor
      , col = c("#0080ff", "gray30")[unclass(wdbc$diagnosis)]
      , labels = rotulos, font.labels = 2, main = "Standard error")
# </code r> ==================================================================== #
@

\newpage
Box plots:

<<fig.width=10, fig.cap='Box plots for each mean variable divided by "Diagnosis".'>>=
# <code r> ===================================================================== #
wdbc_mean <- reshape2::melt(wdbc[1:11], id.vars = "diagnosis")
levels(wdbc_mean$diagnosis) <- c("Benign", "Malignant")
levels(wdbc_mean$variable) <- tm::removeWords(levels(wdbc_mean$variable), "mean ")

bwplot(value ~ diagnosis | variable, wdbc_mean
       , layout = c(4, 3), scales = list(y = list(relation = "free", rot = 0))
       , ylab = NULL, strip = strip.custom(bg = "white"), pch = "|"
       , main = "Mean"
       , par.settings = list(
         box.rectangle = list(
           col = c("#0080ff", "gray60"), fill = c("#0080ff", "gray60")
           , alpha = .6, border = "transparent")
         , box.umbrella = list(col = c("#0080ff", "gray60"))
         , plot.symbol = list(col = "red", pch = 16, alpha = .6)))
# </code r> ==================================================================== #
@

<<fig.width=10, fig.cap='Box plots for each "worst" variable divided by "Diagnosis".'>>=
# <code r> ===================================================================== #
wdbc_worst <- reshape2::melt(wdbc[c(1, 12:21)], id.vars = "diagnosis")
levels(wdbc_worst$diagnosis) <- c("Benign", "Malignant")
levels(wdbc_worst$variable) <-
  tm::removeWords(levels(wdbc_worst$variable), "worst ")

bwplot(value ~ diagnosis | variable, wdbc_worst
       , layout = c(4, 3), scales = list(y = list(relation = "free", rot = 0))
       , ylab = NULL, strip = strip.custom(bg = "white"), pch = "|"
       , main = '"Worst"'
       , par.settings = list(
         box.rectangle = list(
           col = c("#0080ff", "gray60"), fill = c("#0080ff", "gray60")
           , alpha = .6, border = "transparent")
         , box.umbrella = list(col = c("#0080ff", "gray60"))
         , plot.symbol = list(col = "red", pch = 16, alpha = .6)))
# </code r> ==================================================================== #
@

<<fig.width=10, fig.cap='Box plots for each standard error variable divided by "Diagnosis".'>>=
# <code r> ===================================================================== #
wdbc_sd <- reshape2::melt(wdbc[c(1, 22:31)], id.vars = "diagnosis")
levels(wdbc_sd$diagnosis) <- c("Benign", "Malignant")
levels(wdbc_sd$variable) <- tm::removeWords(levels(wdbc_sd$variable), "sd ")

bwplot(value ~ diagnosis | variable, wdbc_sd
       , layout = c(4, 3), scales = list(y = list(relation = "free", rot = 0))
       , ylab = NULL, strip = strip.custom(bg = "white"), pch = "|"
       , main = "Standard error"
       , par.settings = list(
         box.rectangle = list(
           col = c("#0080ff", "gray60"), fill = c("#0080ff", "gray60")
           , alpha = .6, border = "transparent")
         , box.umbrella = list(col = c("#0080ff", "gray60"))
         , plot.symbol = list(col = "red", pch = 16, alpha = .6)))
# </code r> ==================================================================== #
@

Approximatelly 2/3 of the patients were with the exam classified as benign. When
we look to the mean variables, three pairs present a correlation (linear
correspondence) extremaly close to 1. Between this ten variables we see every
behavior types. Relations with a very high correlation, with a medium correlation
and with a very small correlation. In general, the same behavior is seen with the
same variables when we looked to the "worst" and standard error variables. We can
highlight as very high correlations the relations between the variables area and
perimeter, radius and perimeter, and radius and area. As a very small correlation
we can highlight the relations between the variables texture and symmetry, texture
and fractal dimension, area and symmetry, and area and fractal dimension. When we
looked to the box plots, in general, for all the ten variables in the three
different measure types, the biggest values are present in the patients
classified as malignant.

\section*{Exercise 5} \addcontentsline{toc}{section}{Exercise 5}

\horrule{1pt} \\

\textbf{Consider this dataset derived from the Framingham Heart Study where one of
        the goals was to study possible links between high systolic blood pressure
        (SBP) and coronary heart disease (CHD). Participants with SBP \(\geq\) 165
        mm Hg were put in the ”high” SBP category.}

\begin{center}
 \begin{tabular}{|c|c|c|}
  \hline
  & CHD & No CHD \\ \hline
  High SBP & 144 & 62 \\ \hline
  Normal SBP & 120 & 419 \\
  \hline
 \end{tabular}
\end{center}

\subsection*{(a)} \addcontentsline{toc}{subsection}{(a)}

\textbf{\textit{Marginal proportions}. From the table, what is the proportion of
        participants who had CHD? What is the proportion of participants who had
        high SBP?} \\

\underline{Solution:} \\

CHD = 144 + 120 = 264, \quad NoCHD = 62 + 419 = 481, \quad n = CHD + NoCHD = 745
\\

\boxed{\text{Proportion of participants who had CHD: CHD/n = 264/745 = 0.3543624
             (35\%).}} \\

HiSBP = 144 + 62 = 206, \quad NorSBP = 120 + 419 = 539, \\
n = CHD + NoCHD = HiSBP + NorSBP = 745 \\

\boxed{\text{Proportion of participants who had high SBP:
             HiSBP/n = 206/745 = 0.2765101 (28\%).}}
   
\subsection*{(b)} \addcontentsline{toc}{subsection}{(b)}

\textbf{\textit{Conditional proportions}. Among the participants with high SBP,
        what is the proportion of those who also have CHD? Among the participants
        with normal SBP, what is the proportion of those who also have CHD? Does
        this provide some evidence of a link between elevated systolic blood
        pressure and coronary heart disease? Can one now claim that elevated
        systolic blood pressure \underline{causes} coronary heart disease?} \\
        
\underline{Solution:} \\

\fbox{\begin{minipage}{15cm}
       Among the participants with high SBP, the proportion of those who also have
       CHD: \\
       CHD/HiSBP = 144/206 = 0.6990291 (70\%). 
      \end{minipage}} \\

\fbox{\begin{minipage}{15.5cm}
       Among the participants with normal SBP, the proportion of those who also
       have CHD: \\
       CHD/NorSBP = 120/539 = 0.2226345 (22\%). 
      \end{minipage}} \\

Does this provide some evidence of a link between elevated systolic blood pressure
and coronary heart disease? Yes. Because in the patients with normal SBP the
proportion with CHD is 22 percent, almost 1/5, while in the patients with high SBP
the proportion with CHD is 70 percent, much higher. \\

Can one now claim that elevated systolic blood pressure causes coronary heart
disease? No. With this descriptive analysis we can see a possible correlation 
between high SBP and CHD, but this not implies in causality. we don't have enough
information to claim this type of result. Correlation is different form causality.

\subsection*{(c)} \addcontentsline{toc}{subsection}{(c)}

\textbf{\textit{Odds and odds ratios}. Compute the odds of having CHD among the
        high SBP group. Compute the odds of having CHD among the normal SBP group.
        Compute the odds ratio of having CHD for the high SBP vs normal SBP
        groups.} \\
        
\underline{Solution:} \\

\fbox{\begin{minipage}{8.25cm}
       Odds of having CHD among the high SBP group:
       \[ \frac{144/206}{1 - 144/206} = 2.322581. \]
      \end{minipage}} \hfill
\fbox{\begin{minipage}{8.25cm}
       Odds of having CHD among the normal SBP group:
       \[ \frac{120/539}{1 - 120/539} = 0.2863962. \]
      \end{minipage}} \\

\begin{center}
 \fbox{\begin{minipage}{12.25cm}
        Odds ratio of having CHD for the high SBP vs normal SBP groups:
        \[ \frac{2.322581}{0.286396} = 8.109678. \]
       \end{minipage}}
\end{center}

The odds of having CHD for the high SBP groups is 8.11 times of the odds of CHD
for the normal SBP group.

\section*{Exercise 6} \addcontentsline{toc}{section}{Exercise 6}

\horrule{1pt} \\

\textbf{The beetle mortality data. Groups of beetles were exposed to varying doses
        of toxins and the number of deaths (\texttt{ytotal}) out of the total
        exposure (\texttt{ntotal}) were recorded. Enter the variables in R:}

\begin{align*}
 \texttt{dose} & = {\rm c}(1.69, 1.72, 1.75, 1.78, 1.81, 1.84, 1.86, 1.88) \\
 \texttt{ntotal} & = {\rm c}(59, 60, 62, 56, 63, 59, 62, 60) \\
 \texttt{ytotal} & = {\rm c}(6, 13, 18, 28, 52, 53, 61, 60)
\end{align*}

<<>>=
# <code r> ===================================================================== #
dose <- c(1.69, 1.72, 1.75, 1.78, 1.81, 1.84, 1.86, 1.88)
ntotal <- c(59, 60, 62, 56, 63, 59, 62, 60)
ytotal <- c(6, 13, 18, 28, 52, 53, 61, 60)
# </code r> ==================================================================== #
@

\subsection*{(a)} \addcontentsline{toc}{subsection}{(a)}

\textbf{Calculate the proportion of deaths for each dose-group.} \\

\underline{Solution:}

<<>>=
# <code r> ===================================================================== #
rbind(dose, "death proportion" = round(ytotal/ntotal, 2))
# </code r> ==================================================================== #
@

\subsection*{(b)} \addcontentsline{toc}{subsection}{(b)}

\textbf{Plot the proportion of deaths against dose. Describe the trend: is it
        increasing/ decreasing, is there an asymptote feature?} \\

\underline{Solution:}

<<fig.width=10, fig.height=5, fig.cap="Proportion of deaths against dose.">>=
# <code r> ===================================================================== #
xyplot(ytotal/ntotal ~ dose, type = c("p", "l")
       , pch = 19, lwd = 1.5, xlab = "Dose", ylab = "Proportion of deaths"
       , scales = list(x = list(at = dose))
       , panel = function(...){
         panel.abline(v = dose, h = seq(.2, 1, .2), col = "gray70")
         panel.xyplot(...)})
# </code r> ==================================================================== #
@

The trend is increasing. For small doses the proportions are very close to zero,
with the biggest doses the proportions are very close to one. With the last dose 
we have a proportion equal to one, the maximum possible. Whats means that with the
biggest dose all the beetles are dead.

\hfill \(\blacksquare\)

\horrule{.5pt}

\vspace{\fill}

\horrule{1pt} \\

\end{document}